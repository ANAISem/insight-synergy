# API-Konfiguration
HOST=0.0.0.0
PORT=8000

# Ollama-Konfiguration
OLLAMA_API_URL=http://localhost:11434/api
MISTRAL_MODEL_NAME=mistral

# Logging-Konfiguration
LOG_LEVEL=INFO
LOG_FILE=nexus_backend.log

# API Keys f√ºr externe Dienste
PERPLEXITY_API_KEY=your_perplexity_api_key
OPENAI_API_KEY=your_openai_api_key

# Modell-Konfiguration
# PRIMARY_MODEL=gpt-o1-mini
# FALLBACK_MODEL=gpt-4o-mini

# Fallback-Einstellungen
ENABLE_MODEL_FALLBACK=true
ENABLE_INSIGHT_CORE_FALLBACK=true

# Insight Synergy Core Konfiguration
ENABLE_INSIGHT_CORE=true
IS_CORE_ENDPOINT=http://localhost:8080/api/core/completion

# Rate Limiting (Anfragen pro Minute)
# RATE_LIMIT_PERPLEXITY=60
# RATE_LIMIT_OPENAI=100

# API-Endpunkte (nur bei Bedarf anpassen)
# PERPLEXITY_API_BASE=https://api.perplexity.ai
# OPENAI_API_BASE=https://api.openai.com/v1

# Timeout-Einstellungen (in Sekunden)
# PERPLEXITY_TIMEOUT=10
# OPENAI_TIMEOUT=15
# IS_CORE_TIMEOUT=20 