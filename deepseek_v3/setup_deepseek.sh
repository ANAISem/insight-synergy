#!/bin/bash

# DeepSeek-V3 Setup-Skript fÃ¼r Ollama
# Dieses Skript richtet das DeepSeek-V3-Modell mit Ollama ein

echo "ðŸ”„ Starte DeepSeek-V3 Setup..."

# Verzeichnis mit der Modelldefinition
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
MODEL_DIR="/Volumes/NO NAME/ollama_models"

# Sicherstellen, dass Ollama lÃ¤uft
if ! pgrep -x "ollama" > /dev/null; then
    echo "ðŸš€ Starte Ollama-Dienst..."
    OLLAMA_MODELS="$MODEL_DIR" ollama serve &
    
    # Warte kurz, bis der Dienst lÃ¤uft
    sleep 3
fi

echo "ðŸ“¥ Erstelle lokales DeepSeek-V3-Modell mit der Modelldefinition..."
ollama create deepseek:local -f "$SCRIPT_DIR/deepseek-v3.modelfile"

echo "âœ… DeepSeek-V3 lokales Modell ist jetzt eingerichtet!"
echo "ðŸ“‹ VerfÃ¼gbare Modelle:"
ollama list

echo "ðŸ§ª Teste das DeepSeek-V3-Modell mit einem einfachen Prompt..."
ollama run deepseek:local "ErklÃ¤re den Unterschied zwischen kÃ¼nstlicher Intelligenz und maschinellem Lernen in drei SÃ¤tzen."

echo "ðŸŽ‰ Setup abgeschlossen!" 